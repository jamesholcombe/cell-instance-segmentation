{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False\n",
    "# Set this depending on whether running in colab or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    # Add directory above current directory to path\n",
    "    DATAPATH = Path(\"/content/drive/MyDrive/DataSets/data\")\n",
    "\n",
    "else:\n",
    "    import sys; \n",
    "    sys.path.insert(0, '..')\n",
    "    DATAPATH = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-28 19:58:48.397178: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jamesholcombe/git/personal/cell-instance-segmentation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2021-12-28 19:58:48.397213: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Conv2DTranspose,\n",
    "    GaussianNoise,\n",
    "    Lambda,\n",
    "    Dropout,\n",
    "    UpSampling2D,\n",
    ")\n",
    "from keras import backend as K\n",
    "from keras.optimizer_v2 import adam\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import math\n",
    "from scipy.sparse import coo_matrix\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(\n",
    "    mask_rle, shape=(520, 704), color=1\n",
    "):  # function to convert tabular mask data to image\n",
    "    \"\"\"\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height, width, channels) of array to return\n",
    "    color: color for the mask\n",
    "    Returns numpy array (mask)\n",
    "\n",
    "    \"\"\"\n",
    "    s = mask_rle.split()\n",
    "\n",
    "    starts = list(map(lambda x: int(x) - 1, s[0::2]))\n",
    "    lengths = list(map(int, s[1::2]))\n",
    "    ends = [x + y for x, y in zip(starts, lengths)]\n",
    "\n",
    "    img = np.zeros((shape[0] * shape[1]), dtype=np.float32)\n",
    "\n",
    "    for start, end in zip(starts, ends):\n",
    "        img[start:end] = color\n",
    "\n",
    "    return img.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\n",
    "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_directory,\n",
    "        data_path,\n",
    "        to_fit=True,\n",
    "        batch_size=32,\n",
    "        chip_size=180,\n",
    "        dim=(520, 704),\n",
    "    ):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        # self.data = self.data[\n",
    "        #     (self.data[\"height\"] < chip_size) | (self.data[\"width\"] < chip_size)\n",
    "        # ]\n",
    "        # self.data.reset_index(inplace=True)\n",
    "\n",
    "        self.indexes = list(self.data.index)\n",
    "        self.image_ids = self.data[\"id\"].unique()\n",
    "        self.image_indexes = dict(zip(range(len(self.image_ids)), self.image_ids))\n",
    "        self.to_fit = to_fit\n",
    "        self.batch_size = batch_size\n",
    "        self.chip_size = chip_size\n",
    "\n",
    "        # self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.indexes) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        if self.to_fit:\n",
    "            X ,y = self._generate_X_and_Y(indexes)\n",
    "            return X, y\n",
    "\n",
    "    def _generate_X_and_Y(self, indexes):\n",
    "        \"\"\"Generates data containing batch_size images\n",
    "        :param list_IDs_temp: list of label ids to load\n",
    "        :return: batch of images\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialization\n",
    "        \n",
    "        \n",
    "        train = self.data.loc[indexes]\n",
    "        train[\"mask\"] = train[\"annotation\"].apply(rle_decode)\n",
    "        \n",
    "        nonzero_masks = train[\"mask\"].apply(lambda x: np.where(x == 1))\n",
    "        x_nonzeros, y_nonzeros = zip(*nonzero_masks)\n",
    "        train[\"x_min\"] = [x.min() for x in x_nonzeros]\n",
    "        train[\"x_max\"] = [x.max() for x in x_nonzeros]\n",
    "        train[\"y_min\"] = [y.min() for y in y_nonzeros]\n",
    "        train[\"y_max\"] = [y.max() for y in y_nonzeros]\n",
    "        train[\"width\"] = train[\"x_max\"] - train[\"x_min\"]\n",
    "        train[\"height\"] = train[\"y_max\"] - train[\"y_min\"]\n",
    "\n",
    "        train[\"y_cent\"] = train[\"mask\"].apply(lambda x: np.median(np.where(x == 1)[1]))\n",
    "        train[\"x_cent\"] = train[\"mask\"].apply(lambda x: np.median(np.where(x == 1)[0]))\n",
    "                \n",
    "        \n",
    "      \n",
    "\n",
    "        train[\"frac_x\"], _ = zip(*train[\"x_cent\"].apply(math.modf))\n",
    "        train[\"frac_y\"], _ = zip(*train[\"y_cent\"].apply(math.modf))\n",
    "\n",
    "        train[\"x_round_down\"] = (train[\"frac_x\"] < 0.5).astype(int)\n",
    "        train[\"y_round_down\"] = (train[\"frac_y\"] < 0.5).astype(int)\n",
    "\n",
    "        train[\"x1\"] = (np.rint(train[\"x_cent\"] - 90).values).astype(int)\n",
    "        train[\"x2\"] = (np.rint(train[\"x_cent\"] + 90).values).astype(int)\n",
    "        train[\"y1\"] = (np.rint(train[\"y_cent\"] - 90).values).astype(int)\n",
    "        train[\"y2\"] = (np.rint(train[\"y_cent\"] + 90).values).astype(int)\n",
    "\n",
    "        train[\"mask\"] = train.apply(func= lambda x: x[\"mask\"][x[\"x1\"]:x[\"x2\"], x[\"y1\"]:x[\"y2\"]],axis = 1)\n",
    "        train[\"shape\"] = train[\"mask\"].map(np.shape)\n",
    "        train[\"xshape\"], train[\"yshape\"] = zip(*train[\"shape\"])\n",
    "        keep = (train[\"xshape\"].astype(int) == 180) & (train[\"yshape\"].astype(int) == 180) \n",
    "        if not keep.all():\n",
    "     \n",
    "            new_train = train[keep]\n",
    "            notkeep = ~keep\n",
    "            to_copy = new_train.sample(notkeep.sum(),replace = True)\n",
    "            \n",
    "            train = pd.concat([new_train,to_copy])\n",
    "        X = np.empty((self.batch_size, self.chip_size, self.chip_size, 3))\n",
    "        Y = np.empty((self.batch_size, self.chip_size, self.chip_size, 1))\n",
    "        for index, (i, row) in enumerate(train.iterrows()): \n",
    "            \n",
    "            mask = row[\"mask\"]\n",
    "            x1 = row[\"x1\"]\n",
    "            x2 = row[\"x2\"] \n",
    "            y1 = row[\"y1\"]\n",
    "            y2 = row[\"y2\"] \n",
    "            try:\n",
    "                mask = np.reshape(mask,(self.chip_size, self.chip_size,1))\n",
    "            except ValueError:\n",
    "                print(mask.shape)\n",
    "                print(f\"{x1=}\")\n",
    "                print(f\"{x2=}\")\n",
    "                print(f\"{y1=}\")\n",
    "                print(f\"{y2=}\")\n",
    "                raise \n",
    "            \n",
    "            Y[index] = mask\n",
    "            \n",
    "            ID = row[\"id\"]\n",
    "            img = np.repeat(\n",
    "        np.asarray(io.imread(DATAPATH / Path(f\"train/{ID}.png\")))[\n",
    "            :, :, np.newaxis\n",
    "        ],\n",
    "        repeats=3,\n",
    "        axis=2,\n",
    "    )\n",
    "            img = img[x1:x2, y1:y2]\n",
    "            \n",
    "            \n",
    "            img = np.reshape(img,(self.chip_size, self.chip_size,3))\n",
    "            \n",
    "            X[index] = img\n",
    "            \n",
    "\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d_143 (Conv2D)         (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_144 (Conv2D)         (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, None, None, 32)   0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_145 (Conv2D)         (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_146 (Conv2D)         (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, None, None, 32)   0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_147 (Conv2D)         (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_148 (Conv2D)         (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, None, None, 64)   0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_149 (Conv2D)         (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_150 (Conv2D)         (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " conv2d_151 (Conv2D)         (None, None, None, 64)    4160      \n",
      "                                                                 \n",
      " conv2d_152 (Conv2D)         (None, None, None, 64)    4160      \n",
      "                                                                 \n",
      " conv2d_153 (Conv2D)         (None, None, None, 721)   46865     \n",
      "                                                                 \n",
      " lambda_26 (Lambda)          (None, 721)               0         \n",
      "                                                                 \n",
      " lambda_27 (Lambda)          (None, 180, 180, 1)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,105\n",
      "Trainable params: 213,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''parameters of Vec2Instace parametrization'''\n",
    "\n",
    "img_dim = 180 # input dimension \n",
    "out_var = 1 # output bands (single band for mask)\n",
    "hidden_size = 180 # hidden size of vanilla neural network of Vec2Instace\n",
    "num_param = (2*hidden_size + hidden_size) + (hidden_size*out_var + out_var) # total number of parameters in vanilla neural network of Vec2Instace \n",
    "\n",
    "'''Encoder Section'''\n",
    "\n",
    "x_in = Input(shape=(None, None, 3)) # input shape: (height, width, 3 bands of RGB)\n",
    "x_temp = Conv2D(32, (3, 3), activation='relu', padding='same')(x_in)\n",
    "x_temp = Dropout(0.25)(x_temp)\n",
    "x_temp = Conv2D(32, (3, 3), activation='relu', padding='same')(x_temp)\n",
    "x_temp = MaxPooling2D((2,2))(x_temp)\n",
    "x_temp = Conv2D(32, (3, 3), dilation_rate=(2, 2), activation='relu', padding='same')(x_temp) # dilated convolutions\n",
    "x_temp = Dropout(0.25)(x_temp)\n",
    "x_temp = Conv2D(32, (3, 3), dilation_rate=(2, 2), activation='relu', padding='same')(x_temp) # dilated convolutions\n",
    "x_temp = MaxPooling2D((2,2))(x_temp)\n",
    "x_temp = Conv2D(64, (3, 3), dilation_rate=(2, 2), activation='relu', padding='same')(x_temp) # dilated convolutions\n",
    "x_temp = Dropout(0.25)(x_temp)\n",
    "x_temp = Conv2D(64, (3, 3), dilation_rate=(2, 2), activation='relu', padding='same')(x_temp) # dilated convolutions\n",
    "x_temp = MaxPooling2D((2,2))(x_temp)\n",
    "x_temp = Conv2D(64, (3, 3), dilation_rate=(2, 2), activation='relu', padding='same')(x_temp) # dilated convolutions\n",
    "x_temp = Dropout(0.25)(x_temp)\n",
    "x_temp = Conv2D(64, (3, 3), dilation_rate=(2, 2), activation='relu', padding='same')(x_temp) # dilated convolutions\n",
    "\n",
    "x_temp = Conv2D(64, (1, 1), activation='relu', padding='same')(x_temp)\n",
    "x_temp = Conv2D(64, (1, 1), activation='relu', padding='same')(x_temp)\n",
    "x_cnn = Conv2D(num_param, (1, 1), activation='linear', padding='same')(x_temp)  # output bands are corresponding to number of parameters in vanilla neural network (MLP) of Vec2Instace.\n",
    "\n",
    "'''Extracting the vector at the middle from the output of the encoder. This vector parametrize the shape of an instance'''\n",
    "\n",
    "def get_middle_param(arg_in):\n",
    "    mid_idx = tf.shape(arg_in)[1]/2\n",
    "    dec_para = arg_in[:, K.cast(mid_idx,\"int32\"), K.cast(mid_idx,\"int32\"), :]    \n",
    "    return dec_para\n",
    "\n",
    "'''rearranging the vector at the middle as vanilla neural network (MLP) of Vec2Instace'''\n",
    "\n",
    "def decorder2D(arg_in):\n",
    "    \n",
    "    dec_size = tf.shape(arg_in)[0]\n",
    "    \n",
    "    # creating input of vanilla neural network (x and y coordinates)\n",
    "    xx, yy = tf.meshgrid(tf.range(-img_dim/2, img_dim/2), tf.range(-img_dim/2, img_dim/2))\n",
    "    xx = K.transpose(K.flatten(tf.cast(xx,tf.float32)))\n",
    "    yy = K.transpose(K.flatten(tf.cast(yy,tf.float32)))\n",
    "    xx_yy_stack = K.stack((xx, yy), axis=1)\n",
    "    lyr_in = K.tile( K.reshape(xx_yy_stack, (1,img_dim*img_dim,2)), (dec_size,1,1))\n",
    "    \n",
    "    # vanilla neural network (MLP)\n",
    "    lyr_hidden_wgt = K.stack( (arg_in[:, 0:hidden_size],arg_in[:, hidden_size*1:hidden_size*2]), axis=1)\n",
    "    lyr_hidden_b = tf.matmul(tf.ones((dec_size,img_dim*img_dim,1)), K.reshape(arg_in[:,hidden_size*2:hidden_size*3], (dec_size,1,hidden_size)))\n",
    "    lyr_hidden_out = K.tanh( tf.matmul(lyr_in, lyr_hidden_wgt) +  lyr_hidden_b) \n",
    "    \n",
    "    lyr_out_wgt = K.reshape( arg_in[:, hidden_size*3:hidden_size*(3+out_var)], (dec_size,hidden_size,out_var))\n",
    "    lyr_out_b = tf.matmul(tf.ones((dec_size,img_dim*img_dim,1)), K.reshape(arg_in[:, hidden_size*(3+out_var):hidden_size*(3+out_var)+out_var], (dec_size,1,out_var)))\n",
    "    lyr_out = K.sigmoid( tf.matmul(lyr_hidden_out, lyr_out_wgt) + lyr_out_b ) \n",
    "\n",
    "    lyr_out_img = K.reshape( lyr_out, (dec_size,img_dim,img_dim,out_var))\n",
    "    \n",
    "    return lyr_out_img\n",
    "\n",
    "x_temp = Lambda(get_middle_param)(x_cnn)\n",
    "x_out = Lambda(decorder2D)(x_temp)\n",
    "\n",
    "model = Model(inputs=x_in, outputs=x_out)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss = 'mse',\n",
    "    metrics=['mean_squared_error']\n",
    ")\n",
    "# model.compile(loss=RootMeanSquaredError, optimizer=adam.Adam()) # setting loss and optimizer\n",
    "\n",
    "model.summary() # printing the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/4\n",
      "4768\n",
      "5344\n",
      "   1/2299 [..............................] - ETA: 1:41:20 - loss: 0.4754 - mean_squared_error: 0.475466720\n",
      "   2/2299 [..............................] - ETA: 1:22:07 - loss: 0.4608 - mean_squared_error: 0.460873280\n",
      "   3/2299 [..............................] - ETA: 1:23:18 - loss: 0.4526 - mean_squared_error: 0.452645344\n",
      "   4/2299 [..............................] - ETA: 1:26:56 - loss: 0.4378 - mean_squared_error: 0.437831456\n",
      "   5/2299 [..............................] - ETA: 1:26:39 - loss: 0.4264 - mean_squared_error: 0.426413280\n",
      "   6/2299 [..............................] - ETA: 1:29:47 - loss: 0.4164 - mean_squared_error: 0.416440928\n",
      "   7/2299 [..............................] - ETA: 1:29:22 - loss: 0.4031 - mean_squared_error: 0.403133760\n",
      "   8/2299 [..............................] - ETA: 1:31:35 - loss: 0.3895 - mean_squared_error: 0.389510016\n",
      "   9/2299 [..............................] - ETA: 1:31:12 - loss: 0.3797 - mean_squared_error: 0.379721120\n",
      "  10/2299 [..............................] - ETA: 1:31:54 - loss: 0.3687 - mean_squared_error: 0.36878832\n",
      "  11/2299 [..............................] - ETA: 1:31:30 - loss: 0.3603 - mean_squared_error: 0.360323328\n",
      "  12/2299 [..............................] - ETA: 1:32:02 - loss: 0.3516 - mean_squared_error: 0.351611712\n",
      "  13/2299 [..............................] - ETA: 1:31:48 - loss: 0.3417 - mean_squared_error: 0.341764032\n",
      "  14/2299 [..............................] - ETA: 1:32:25 - loss: 0.3319 - mean_squared_error: 0.331961888\n",
      "  15/2299 [..............................] - ETA: 1:31:59 - loss: 0.3240 - mean_squared_error: 0.324025408\n",
      "  16/2299 [..............................] - ETA: 1:31:52 - loss: 0.3163 - mean_squared_error: 0.316317312\n",
      "  17/2299 [..............................] - ETA: 1:31:19 - loss: 0.3072 - mean_squared_error: 0.307241056\n",
      "  18/2299 [..............................] - ETA: 1:31:48 - loss: 0.2960 - mean_squared_error: 0.296014688\n",
      "  19/2299 [..............................] - ETA: 1:32:27 - loss: 0.2880 - mean_squared_error: 0.288041024\n",
      "  20/2299 [..............................] - ETA: 1:32:24 - loss: 0.2780 - mean_squared_error: 0.278071168\n",
      "  21/2299 [..............................] - ETA: 1:32:01 - loss: 0.2685 - mean_squared_error: 0.268564544\n",
      "  22/2299 [..............................] - ETA: 1:32:09 - loss: 0.2609 - mean_squared_error: 0.260931488\n",
      "  23/2299 [..............................] - ETA: 1:31:46 - loss: 0.2528 - mean_squared_error: 0.252855264\n",
      "  24/2299 [..............................] - ETA: 1:31:34 - loss: 0.2451 - mean_squared_error: 0.245110656\n",
      "  25/2299 [..............................] - ETA: 1:31:27 - loss: 0.2385 - mean_squared_error: 0.238524672\n",
      "  26/2299 [..............................] - ETA: 1:31:30 - loss: 0.2308 - mean_squared_error: 0.230869216\n",
      "  27/2299 [..............................] - ETA: 1:31:53 - loss: 0.2232 - mean_squared_error: 0.22329728\n",
      "  28/2299 [..............................] - ETA: 1:31:56 - loss: 0.2169 - mean_squared_error: 0.216936512\n",
      "  29/2299 [..............................] - ETA: 1:31:35 - loss: 0.2107 - mean_squared_error: 0.210747584\n",
      "  30/2299 [..............................] - ETA: 1:31:08 - loss: 0.2045 - mean_squared_error: 0.204539712\n",
      "  31/2299 [..............................] - ETA: 1:31:08 - loss: 0.1988 - mean_squared_error: 0.198872672\n",
      "  32/2299 [..............................] - ETA: 1:31:14 - loss: 0.1937 - mean_squared_error: 0.193713600\n",
      "  33/2299 [..............................] - ETA: 1:31:15 - loss: 0.1899 - mean_squared_error: 0.189926944\n",
      "  34/2299 [..............................] - ETA: 1:30:46 - loss: 0.1847 - mean_squared_error: 0.18473424\n",
      "  35/2299 [..............................] - ETA: 1:30:26 - loss: 0.1797 - mean_squared_error: 0.179770880\n",
      "  36/2299 [..............................] - ETA: 1:29:59 - loss: 0.1753 - mean_squared_error: 0.175357792\n",
      "  37/2299 [..............................] - ETA: 1:29:38 - loss: 0.1710 - mean_squared_error: 0.171018848\n",
      "  38/2299 [..............................] - ETA: 1:29:15 - loss: 0.1669 - mean_squared_error: 0.166945568\n",
      "  39/2299 [..............................] - ETA: 1:28:57 - loss: 0.1630 - mean_squared_error: 0.163011744\n",
      "  40/2299 [..............................] - ETA: 1:28:41 - loss: 0.1594 - mean_squared_error: 0.159438208\n",
      "  41/2299 [..............................] - ETA: 1:28:20 - loss: 0.1561 - mean_squared_error: 0.156138944\n",
      "  42/2299 [..............................] - ETA: 1:28:07 - loss: 0.1526 - mean_squared_error: 0.152663904\n",
      "  43/2299 [..............................] - ETA: 1:27:45 - loss: 0.1494 - mean_squared_error: 0.149462816\n",
      "  44/2299 [..............................] - ETA: 1:27:25 - loss: 0.1462 - mean_squared_error: 0.146250656\n",
      "  45/2299 [..............................] - ETA: 1:27:14 - loss: 0.1432 - mean_squared_error: 0.14326176\n",
      "  46/2299 [..............................] - ETA: 1:27:01 - loss: 0.1406 - mean_squared_error: 0.140648512\n",
      "  47/2299 [..............................] - ETA: 1:26:50 - loss: 0.1378 - mean_squared_error: 0.137821600\n",
      "  48/2299 [..............................] - ETA: 1:26:34 - loss: 0.1353 - mean_squared_error: 0.135321760\n",
      "  49/2299 [..............................] - ETA: 1:26:21 - loss: 0.1327 - mean_squared_error: 0.132743488\n",
      "  50/2299 [..............................] - ETA: 1:26:10 - loss: 0.1302 - mean_squared_error: 0.130252320\n",
      "  51/2299 [..............................] - ETA: 1:25:58 - loss: 0.1278 - mean_squared_error: 0.127836832\n",
      "  52/2299 [..............................] - ETA: 1:25:51 - loss: 0.1255 - mean_squared_error: 0.125549760\n",
      "  53/2299 [..............................] - ETA: 1:25:50 - loss: 0.1233 - mean_squared_error: 0.123349216\n",
      "  54/2299 [..............................] - ETA: 1:25:58 - loss: 0.1212 - mean_squared_error: 0.121218080\n",
      "  55/2299 [..............................] - ETA: 1:25:53 - loss: 0.1192 - mean_squared_error: 0.119247680\n",
      "  56/2299 [..............................] - ETA: 1:25:54 - loss: 0.1172 - mean_squared_error: 0.117235840\n",
      "  57/2299 [..............................] - ETA: 1:25:52 - loss: 0.1155 - mean_squared_error: 0.115542432\n",
      "  58/2299 [..............................] - ETA: 1:25:49 - loss: 0.1137 - mean_squared_error: 0.113735424\n",
      "  59/2299 [..............................] - ETA: 1:25:51 - loss: 0.1119 - mean_squared_error: 0.111944288\n",
      "  60/2299 [..............................] - ETA: 1:25:49 - loss: 0.1101 - mean_squared_error: 0.110168448\n",
      "  61/2299 [..............................] - ETA: 1:25:49 - loss: 0.1084 - mean_squared_error: 0.108451200\n",
      "  62/2299 [..............................] - ETA: 1:25:46 - loss: 0.1068 - mean_squared_error: 0.106831264\n",
      "  63/2299 [..............................] - ETA: 1:25:47 - loss: 0.1052 - mean_squared_error: 0.105231936\n",
      "  64/2299 [..............................] - ETA: 1:25:58 - loss: 0.1037 - mean_squared_error: 0.103748064\n",
      "  65/2299 [..............................] - ETA: 1:26:05 - loss: 0.1022 - mean_squared_error: 0.102250752\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1531/100856315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model.fit(data_gen, epochs=50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/personal/cell-instance-segmentation/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/personal/cell-instance-segmentation/venv/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/personal/cell-instance-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/personal/cell-instance-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/personal/cell-instance-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/personal/cell-instance-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/personal/cell-instance-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/git/personal/cell-instance-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/personal/cell-instance-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_gen = DataGenerator(\n",
    "    DATAPATH / Path(\"train\"),\n",
    "    DATAPATH / Path(\"train/.csv\"),\n",
    ")\n",
    "# model.fit(data_gen, epochs=50)\n",
    "model.fit(data_gen,epochs=4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d38d43298adb51ba826b6e7da8ec99b7c56c60df20ebcb18ac2c959eba92e68"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
